import sys
import json
import torch
import flwr as fl
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from simpleCNN import DeepCNN

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# π”Ή μ‚¬μ©μ μ •μ FEMNIST λ°μ΄ν„°μ…‹ ν΄λμ¤
class FEMNISTDataset(Dataset):
    def __init__(self, images, labels):
        self.images = images
        self.labels = labels

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        return self.images[idx], self.labels[idx]

# π”Ή FEMNIST λ°μ΄ν„° λ΅λ“ ν•¨μ
def load_femnist_data(path):
    with open(path, 'r') as f:
        data = json.load(f)
    user_key = list(data['user_data'].keys())[0]
    images = torch.tensor(data['user_data'][user_key]['x']).reshape(-1, 1, 28, 28).float()
    labels = torch.tensor(data['user_data'][user_key]['y']).long()
    return images, labels

# π”Ή Flower ν΄λΌμ΄μ–ΈνΈ ν΄λμ¤ (FedSGD κµ¬ν„)
class FLClient(fl.client.NumPyClient):
    def __init__(self, model, trainloader, testloader):
        self.model = model.to(device) 
        self.trainloader = trainloader
        self.testloader = testloader
        self.criterion = nn.CrossEntropyLoss()

    def get_parameters(self):
        """λ¨λΈ νλΌλ―Έν„°λ¥Ό NumPy λ°°μ—΄λ΅ λ°ν™"""
        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]

    def set_parameters(self, parameters):
        """NumPy λ°°μ—΄λ΅ μ „λ‹¬λ°›μ€ νλΌλ―Έν„°λ¥Ό λ¨λΈμ— μ„¤μ •"""
        state_dict = self.model.state_dict()
        for key, val in zip(state_dict.keys(), parameters):
            state_dict[key] = torch.tensor(val)
        self.model.load_state_dict(state_dict)

    def train(self):
        """FedSGD: ν• λ²μ SGD μ—…λ°μ΄νΈλ§ μν–‰"""
        self.model.train()
        
        # μ²« λ²μ§Έ λ―Έλ‹λ°°μΉμ—μ„ ν• λ²μ SGD μ—…λ°μ΄νΈλ§ μν–‰
        for images, labels in self.trainloader:
            images, labels = images.to(device), labels.to(device)
            optimizer = optim.SGD(self.model.parameters(), lr=0.05)  # ν•™μµλ¥  μ„¤μ •
            optimizer.zero_grad()
            output = self.model(images)
            loss = self.criterion(output, labels)
            loss.backward()
            optimizer.step()
            break  # ν• λ²μ μ—…λ°μ΄νΈλ§ μν–‰
        
        return self.get_parameters()

    def evaluate_model(self):
        """λ¨λΈ ν‰κ°€: μ •ν™•λ„μ™€ μ†μ‹¤ κ³„μ‚°"""
        self.model.eval()
        correct, total, loss = 0, 0, 0.0
        with torch.no_grad():
            for images, labels in self.testloader:
                images, labels = images.to(device), labels.to(device)
                outputs = self.model(images)
                loss += self.criterion(outputs, labels).item()
                correct += (outputs.argmax(1) == labels).sum().item()
                total += labels.size(0)
        
        acc = correct / total if total > 0 else 0.0
        print(f"[CLIENT EVAL] Accuracy: {correct}/{total} = {acc:.4f}")
        
        return loss / len(self.testloader), acc

    def fit(self, parameters, config):
        """FedSGD ν•™μµ: ν• λ²μ SGD μ—…λ°μ΄νΈ μν–‰ ν›„ νλΌλ―Έν„° λ°ν™"""
        self.set_parameters(parameters)  # μ„λ²„μ—μ„ μ „λ‹¬λ°›μ€ νλΌλ―Έν„° μ„¤μ •
        updated_parameters = self.train()  # ν• λ²μ SGD μ—…λ°μ΄νΈ μν–‰
        
        return updated_parameters, len(self.trainloader.dataset), {}

    def evaluate(self, parameters, config):
        """λ¨λΈ ν‰κ°€: μ†μ‹¤κ³Ό μ •ν™•λ„ λ°ν™"""
        self.set_parameters(parameters)  # μ„λ²„μ—μ„ μ „λ‹¬λ°›μ€ νλΌλ―Έν„° μ„¤μ •
        loss, accuracy = self.evaluate_model()  # λ¨λΈ ν‰κ°€
        
        return float(loss), len(self.testloader.dataset), {"accuracy": float(accuracy)}

# π”Ή μ‹¤ν–‰ μ‹μ‘
if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("β— ν΄λΌμ΄μ–ΈνΈ μ‹¤ν–‰ μ‹ ν•™μµ λ°μ΄ν„° κ²½λ΅λ¥Ό μΈμλ΅ μ „λ‹¬ν•΄μ•Ό ν•©λ‹λ‹¤.")
        sys.exit(1)

    # ν•™μµ λ°μ΄ν„° λ΅λ“ λ° DataLoader μƒμ„±
    train_path = sys.argv[1]
    train_images, train_labels = load_femnist_data(train_path)
    trainloader = DataLoader(FEMNISTDataset(train_images, train_labels), batch_size=32, shuffle=True)

    # ν…μ¤νΈ λ°μ΄ν„° λ΅λ“ λ° DataLoader μƒμ„± (ν…μ¤νΈ λ°μ΄ν„°κ°€ μ—†μ„ κ²½μ° ν•™μµ λ°μ΄ν„°λ¥Ό μ‚¬μ©)
    test_path = train_path.replace("train", "test").replace("_train_", "_test_")
    try:
        test_images, test_labels = load_femnist_data(test_path)
    except FileNotFoundError:
        print(f"β— ν…μ¤νΈ λ°μ΄ν„° νμΌμ„ μ°Ύμ„ μ μ—†μµλ‹λ‹¤: {test_path}")
        test_images, test_labels = train_images, train_labels  # fallback to training data
    
    testloader = DataLoader(FEMNISTDataset(test_images, test_labels), batch_size=32, shuffle=False)

    # λ¨λΈ λ° ν΄λΌμ΄μ–ΈνΈ μ΄κΈ°ν™”
    model = DeepCNN()
    client = FLClient(model=model, trainloader=trainloader, testloader=testloader)

    # Flower ν΄λΌμ΄μ–ΈνΈ μ‹μ‘ (FedSGD λ°©μ‹μΌλ΅ λ™μ‘)
    fl.client.start_numpy_client(server_address="127.0.0.1:8080", client=client)
