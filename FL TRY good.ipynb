{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Federated SGD\n",
      "\n",
      "=== Round 1/25 - FedSGD ===\n",
      "Sampled Clients: [3 2 1]\n",
      "\n",
      "=== Round 2/25 - FedSGD ===\n",
      "Sampled Clients: [1 2 0]\n",
      "\n",
      "=== Round 3/25 - FedSGD ===\n",
      "Sampled Clients: [4 3 0]\n",
      "\n",
      "=== Round 4/25 - FedSGD ===\n",
      "Sampled Clients: [3 2 1]\n",
      "\n",
      "=== Round 5/25 - FedSGD ===\n",
      "Sampled Clients: [3 1 2]\n",
      "\n",
      "=== Round 6/25 - FedSGD ===\n",
      "Sampled Clients: [4 0 2]\n",
      "\n",
      "=== Round 7/25 - FedSGD ===\n",
      "Sampled Clients: [2 1 4]\n",
      "\n",
      "=== Round 8/25 - FedSGD ===\n",
      "Sampled Clients: [1 0 4]\n",
      "\n",
      "=== Round 9/25 - FedSGD ===\n",
      "Sampled Clients: [0 4 3]\n",
      "\n",
      "=== Round 10/25 - FedSGD ===\n",
      "Sampled Clients: [2 1 0]\n",
      "\n",
      "=== Round 11/25 - FedSGD ===\n",
      "Sampled Clients: [1 0 4]\n",
      "\n",
      "=== Round 12/25 - FedSGD ===\n",
      "Sampled Clients: [4 0 1]\n",
      "\n",
      "=== Round 13/25 - FedSGD ===\n",
      "Sampled Clients: [4 0 2]\n",
      "\n",
      "=== Round 14/25 - FedSGD ===\n",
      "Sampled Clients: [2 0 3]\n",
      "\n",
      "=== Round 15/25 - FedSGD ===\n",
      "Sampled Clients: [3 4 2]\n",
      "\n",
      "=== Round 16/25 - FedSGD ===\n",
      "Sampled Clients: [0 2 3]\n",
      "\n",
      "=== Round 17/25 - FedSGD ===\n",
      "Sampled Clients: [3 1 0]\n",
      "\n",
      "=== Round 18/25 - FedSGD ===\n",
      "Sampled Clients: [0 3 4]\n",
      "\n",
      "=== Round 19/25 - FedSGD ===\n",
      "Sampled Clients: [2 0 4]\n",
      "\n",
      "=== Round 20/25 - FedSGD ===\n",
      "Sampled Clients: [4 2 1]\n",
      "\n",
      "=== Round 21/25 - FedSGD ===\n",
      "Sampled Clients: [3 4 1]\n",
      "\n",
      "=== Round 22/25 - FedSGD ===\n",
      "Sampled Clients: [3 0 2]\n",
      "\n",
      "=== Round 23/25 - FedSGD ===\n",
      "Sampled Clients: [3 4 0]\n",
      "\n",
      "=== Round 24/25 - FedSGD ===\n",
      "Sampled Clients: [0 1 4]\n",
      "\n",
      "=== Round 25/25 - FedSGD ===\n",
      "Sampled Clients: [4 0 2]\n",
      "\n",
      "Starting Federated Averaging\n",
      "\n",
      "=== Round 1/25 - FedAvg ===\n",
      "Sampled Clients: [3 4 2]\n",
      "\n",
      "=== Round 2/25 - FedAvg ===\n",
      "Sampled Clients: [3 0 1]\n",
      "\n",
      "=== Round 3/25 - FedAvg ===\n",
      "Sampled Clients: [4 1 3]\n",
      "\n",
      "=== Round 4/25 - FedAvg ===\n",
      "Sampled Clients: [3 1 0]\n",
      "\n",
      "=== Round 5/25 - FedAvg ===\n",
      "Sampled Clients: [2 1 3]\n",
      "\n",
      "=== Round 6/25 - FedAvg ===\n",
      "Sampled Clients: [0 1 2]\n",
      "\n",
      "=== Round 7/25 - FedAvg ===\n",
      "Sampled Clients: [1 2 4]\n",
      "\n",
      "=== Round 8/25 - FedAvg ===\n",
      "Sampled Clients: [3 0 1]\n",
      "\n",
      "=== Round 9/25 - FedAvg ===\n",
      "Sampled Clients: [4 3 2]\n",
      "\n",
      "=== Round 10/25 - FedAvg ===\n",
      "Sampled Clients: [2 4 3]\n",
      "\n",
      "=== Round 11/25 - FedAvg ===\n",
      "Sampled Clients: [1 2 0]\n",
      "\n",
      "=== Round 12/25 - FedAvg ===\n",
      "Sampled Clients: [2 0 3]\n",
      "\n",
      "=== Round 13/25 - FedAvg ===\n",
      "Sampled Clients: [2 1 3]\n",
      "\n",
      "=== Round 14/25 - FedAvg ===\n",
      "Sampled Clients: [3 1 4]\n",
      "\n",
      "=== Round 15/25 - FedAvg ===\n",
      "Sampled Clients: [3 1 0]\n",
      "\n",
      "=== Round 16/25 - FedAvg ===\n",
      "Sampled Clients: [4 3 1]\n",
      "\n",
      "=== Round 17/25 - FedAvg ===\n",
      "Sampled Clients: [0 4 3]\n",
      "\n",
      "=== Round 18/25 - FedAvg ===\n",
      "Sampled Clients: [1 0 4]\n",
      "\n",
      "=== Round 19/25 - FedAvg ===\n",
      "Sampled Clients: [1 2 0]\n",
      "\n",
      "=== Round 20/25 - FedAvg ===\n",
      "Sampled Clients: [1 0 4]\n",
      "\n",
      "=== Round 21/25 - FedAvg ===\n",
      "Sampled Clients: [3 2 0]\n",
      "\n",
      "=== Round 22/25 - FedAvg ===\n",
      "Sampled Clients: [3 2 1]\n",
      "\n",
      "=== Round 23/25 - FedAvg ===\n",
      "Sampled Clients: [2 3 4]\n",
      "\n",
      "=== Round 24/25 - FedAvg ===\n",
      "Sampled Clients: [1 3 2]\n",
      "\n",
      "=== Round 25/25 - FedAvg ===\n",
      "Sampled Clients: [1 4 3]\n",
      "\n",
      "Evaluating Federated SGD Model\n",
      "Test Accuracy: 19.05%\n",
      "Mean Client Accuracy: 6.82%\n",
      "Median Client Accuracy: 4.69%\n",
      "Max Client Accuracy: 19.05%\n",
      "\n",
      "Evaluating Federated AVG Model\n",
      "Test Accuracy: 85.71%\n",
      "Mean Client Accuracy: 79.91%\n",
      "Median Client Accuracy: 82.81%\n",
      "Max Client Accuracy: 85.71%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torchvision import transforms\n",
    "\n",
    "# FEMNIST 데이터셋 정의\n",
    "class FEMNISTDataset(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "\n",
    "        # JSON 파일 로드\n",
    "        with open(data_path, 'r') as f:\n",
    "            raw_data = json.load(f)\n",
    "\n",
    "        # 데이터와 레이블 추출\n",
    "        for user_data in raw_data['user_data'].values():\n",
    "            self.data.extend(user_data['x'])\n",
    "            self.labels.extend(user_data['y'])\n",
    "\n",
    "        # 이미지 전처리\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,))  # Normalize: 픽셀 값을 -1 ~ 1로 스케일링\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = np.array(self.data[idx], dtype=np.float32).reshape(28, 28)\n",
    "        label = self.labels[idx]\n",
    "        image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# 간단한 CNN 모델 정의\n",
    "def SimpleCNN():\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2),\n",
    "        nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(64 * 7 * 7, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 62)\n",
    "    )\n",
    "\n",
    "# Federated SGD Implementation\n",
    "def federated_sgd(global_model, client_loaders, num_rounds, client_fraction, lr):\n",
    "    for round_num in range(num_rounds):\n",
    "        print(f\"\\n=== Round {round_num + 1}/{num_rounds} - FedSGD ===\")\n",
    "\n",
    "        # 2. Client Sampling\n",
    "        sampled_clients = np.random.choice(\n",
    "            range(len(client_loaders)),\n",
    "            int(client_fraction * len(client_loaders)),\n",
    "            replace=False\n",
    "        )\n",
    "        print(f\"Sampled Clients: {sampled_clients}\")\n",
    "\n",
    "        global_gradient = None\n",
    "\n",
    "        # 3. Local Learning (Compute Gradients)\n",
    "        for client_idx in sampled_clients:\n",
    "            client_loader = client_loaders[client_idx]\n",
    "            model = SimpleCNN()\n",
    "            model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "            optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "            model.train()\n",
    "            for batch in client_loader:\n",
    "                images, labels = batch\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                break  # Only one mini-batch for FedSGD\n",
    "\n",
    "            # Aggregate gradients\n",
    "            if global_gradient is None:\n",
    "                global_gradient = [param.grad.clone() for param in model.parameters()]\n",
    "            else:\n",
    "                for g, param in zip(global_gradient, model.parameters()):\n",
    "                    g += param.grad\n",
    "\n",
    "        # 4. Update Global Parameters\n",
    "        for param, grad in zip(global_model.parameters(), global_gradient):\n",
    "            param.data -= lr * (grad / len(sampled_clients))\n",
    "\n",
    "# Federated Averaging Implementation\n",
    "def federated_avg(global_model, client_loaders, num_rounds, client_fraction, num_epochs, lr):\n",
    "    for round_num in range(num_rounds):\n",
    "        print(f\"\\n=== Round {round_num + 1}/{num_rounds} - FedAvg ===\")\n",
    "\n",
    "        # 2. Client Sampling\n",
    "        sampled_clients = np.random.choice(\n",
    "            range(len(client_loaders)),\n",
    "            int(client_fraction * len(client_loaders)),\n",
    "            replace=False\n",
    "        )\n",
    "        print(f\"Sampled Clients: {sampled_clients}\")\n",
    "\n",
    "        client_weights = []\n",
    "\n",
    "        # 3. Local Learning (Compute Weights)\n",
    "        for client_idx in sampled_clients:\n",
    "            client_loader = client_loaders[client_idx]\n",
    "            model = SimpleCNN()\n",
    "            model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "            optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "            model.train()\n",
    "            for _ in range(num_epochs):\n",
    "                for batch in client_loader:\n",
    "                    images, labels = batch\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            client_weights.append({k: v.clone() for k, v in model.state_dict().items()})\n",
    "\n",
    "        # 4. Update Global Parameters (Weighted Average)\n",
    "        global_state_dict = global_model.state_dict()\n",
    "        for key in global_state_dict.keys():\n",
    "            global_state_dict[key] = sum([client[key] for client in client_weights]) / len(client_weights)\n",
    "        global_model.load_state_dict(global_state_dict)\n",
    "\n",
    "# 테스트 데이터 평가 함수\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    total, correct = 0, 0\n",
    "    client_accuracies = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            accuracy = 100 * (predicted == labels).sum().item() / labels.size(0)\n",
    "            client_accuracies.append(accuracy)\n",
    "            \n",
    "    overall_accuracy = 100 * correct / total\n",
    "    mean_accuracy = np.mean(client_accuracies)\n",
    "    median_accuracy = np.median(client_accuracies)\n",
    "    max_accuracy = np.max(client_accuracies)\n",
    "    \n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Mean Client Accuracy: {mean_accuracy:.2f}%\")\n",
    "    print(f\"Median Client Accuracy: {median_accuracy:.2f}%\")\n",
    "    print(f\"Max Client Accuracy: {max_accuracy:.2f}%\")\n",
    "    \n",
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    # 클라이언트별 데이터 경로\n",
    "    client_data_paths = [\n",
    "        'C:/Users/ahsld/leaf/data/femnist/data/train/all_data_0_niid_05_keep_5_train_9.json',\n",
    "        'C:/Users/ahsld/leaf/data/femnist/data/train/all_data_1_niid_05_keep_5_train_9.json',\n",
    "        'C:/Users/ahsld/leaf/data/femnist/data/train/all_data_2_niid_05_keep_5_train_9.json',\n",
    "        'C:/Users/ahsld/leaf/data/femnist/data/train/all_data_3_niid_05_keep_5_train_9.json',\n",
    "        'C:/Users/ahsld/leaf/data/femnist/data/train/all_data_4_niid_05_keep_5_train_9.json'\n",
    "    ]\n",
    "\n",
    "    # 클라이언트별 DataLoader 생성\n",
    "    client_loaders = [DataLoader(FEMNISTDataset(path), batch_size=32, shuffle=True) for path in client_data_paths]\n",
    "\n",
    "    # 테스트 데이터 경로 및 로더 생성\n",
    "    test_data_path = 'C:/Users/ahsld/leaf/data/femnist/data/test/all_data_0_niid_05_keep_5_test_9.json'\n",
    "    test_loader = DataLoader(FEMNISTDataset(test_data_path), batch_size=32)\n",
    "\n",
    "    # 글로벌 모델 초기화\n",
    "    SGD_Global = SimpleCNN()\n",
    "    AVG_Global = SimpleCNN()\n",
    "\n",
    "    # Federated SGD\n",
    "    print(\"Starting Federated SGD\")\n",
    "    federated_sgd(SGD_Global, client_loaders, num_rounds=25, client_fraction=0.75, lr=0.01)\n",
    "\n",
    "    # Federated Averaging\n",
    "    print(\"\\nStarting Federated Averaging\")\n",
    "    federated_avg(AVG_Global, client_loaders, num_rounds=25, client_fraction=0.75, num_epochs=5, lr=0.01)\n",
    "\n",
    "    # 모델 평가\n",
    "    print(\"\\nEvaluating Federated SGD Model\")\n",
    "    evaluate_model(SGD_Global, test_loader)\n",
    "\n",
    "    print(\"\\nEvaluating Federated AVG Model\")\n",
    "    evaluate_model(AVG_Global, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GGG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
